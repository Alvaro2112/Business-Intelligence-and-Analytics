{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Walkthrough_Classification_2_.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/Business-Intelligence-and-Analytics/blob/master/%20week10%20-%20Classification2%20/%20Walkthrough_Classification_2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yqS3Z6AtqrmH"
      },
      "source": [
        "# Classification\n",
        "\n",
        "For classification we can use different algorithms, for example: \n",
        "- Logisitic regression (seen last week)\n",
        "- K-Nearest Neighbours\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "- Gradient Descent\n",
        "- etc. \n",
        "\n",
        "This week we will cover **K-Nearest Neighbours** and **Decision Trees**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kPrU-9xrG0vz"
      },
      "source": [
        "For the walkthrough we will use the same dataset as last week and show new classification algorithms. Independently on which algorithm we use we need always to: \n",
        "- load our data set\n",
        "- define our dependent and independent variables\n",
        "- split our data set into train and test subsets\n",
        "- normalize our data set\n",
        "- create the model (regression, KNN, decision tree, ...)\n",
        "- train our model \n",
        "- check the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rjbMSebFfy3F",
        "outputId": "483197f2-3a8d-4848-8aad-2a424b76d7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Load dataset\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "url = 'https://raw.githubusercontent.com/michalis0/Business-Intelligence-and-Analytics/master/week9%20/data/fruit_data_with_colors_2classes.csv'\n",
        "fruits = pd.read_csv(url,sep=\";\")\n",
        "fruits.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fruit_label</th>\n",
              "      <th>fruit_name</th>\n",
              "      <th>fruit_subtype</th>\n",
              "      <th>mass</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>color_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>apple</td>\n",
              "      <td>granny_smith</td>\n",
              "      <td>192</td>\n",
              "      <td>8.4</td>\n",
              "      <td>7.3</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>apple</td>\n",
              "      <td>granny_smith</td>\n",
              "      <td>180</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>apple</td>\n",
              "      <td>granny_smith</td>\n",
              "      <td>176</td>\n",
              "      <td>7.4</td>\n",
              "      <td>7.2</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>apple</td>\n",
              "      <td>braeburn</td>\n",
              "      <td>178</td>\n",
              "      <td>7.1</td>\n",
              "      <td>7.8</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>apple</td>\n",
              "      <td>braeburn</td>\n",
              "      <td>172</td>\n",
              "      <td>7.4</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fruit_label fruit_name fruit_subtype  mass  width  height  color_score\n",
              "0            1      apple  granny_smith   192    8.4     7.3         0.55\n",
              "1            1      apple  granny_smith   180    8.0     6.8         0.59\n",
              "2            1      apple  granny_smith   176    7.4     7.2         0.60\n",
              "3            1      apple      braeburn   178    7.1     7.8         0.92\n",
              "4            1      apple      braeburn   172    7.4     7.0         0.89"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TO_08h8zl3Wm",
        "colab": {}
      },
      "source": [
        "#Define features and target variable\n",
        "feature_names = ['mass', 'width', 'height', 'color_score']\n",
        "X = fruits[feature_names]\n",
        "y = fruits['fruit_label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dK_lptPte5pu"
      },
      "source": [
        "Let's see the different classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fe_eDCBIe5pv",
        "outputId": "2dd6d20b-b0da-41ed-875b-30a85d5bfb82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(fruits['fruit_name'].unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['apple' 'orange']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tlUPoK3Ie5pz"
      },
      "source": [
        "Same as last week, we are going to try a fruit (find its name) using features like its mass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AkF9wmujkOmZ"
      },
      "source": [
        "#### 1) Split into train and test set\n",
        " \n",
        "The data is split into random train and test subsets. The training set contains a known output and the model learns on this data in order to be generalized to other data later on. We use the test dataset in order to test our prediction on this subset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0KxeLYcbf0wx",
        "colab": {}
      },
      "source": [
        "#Split data set into a train and a test data sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oWsiJT07Gt7c"
      },
      "source": [
        "#### 2) Normalization\n",
        "\n",
        "When we have a dataset with features that have very distinct ranges (for example one feature where age is between 0 and 99 year and another feature being the income raning from 1'000CHF to 200'000CHF) we might get biaised results. We want the features to be in the same or similar ranges. Therefore, we **normalize** the data. It involves scaling all values for a specific feature given attribute so that they fall within a small specified range.\n",
        "We can use *StandardScaler()*, *MinMaxScaler* () or others for normalization.\n",
        "<br>\n",
        "\n",
        "In our example we will normalize our **train AND test data** using MinMaxScaler.\n",
        "\n",
        "/!\\ **IMPORTANT**: When you normalize the train data, you need to do the same modificaiton (here normalization) to the test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xVOubyMJ7-HX",
        "outputId": "04c3f432-93ee-4fbd-fac5-6576398cf9d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "#Define normalization \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09009009, 0.13793103, 0.30769231, 0.55263158],\n",
              "       [0.08108108, 0.17241379, 0.38461538, 0.57894737],\n",
              "       [0.06306306, 0.20689655, 0.19230769, 0.63157895],\n",
              "       [0.06306306, 0.17241379, 0.15384615, 0.71052632],\n",
              "       [0.06306306, 0.13793103, 0.26923077, 0.60526316],\n",
              "       [0.04504505, 0.13793103, 0.42307692, 0.52631579],\n",
              "       [0.01801802, 0.03448276, 0.23076923, 0.52631579],\n",
              "       [0.10810811, 0.20689655, 0.34615385, 0.39473684],\n",
              "       [0.0990991 , 0.27586207, 0.11538462, 0.73684211],\n",
              "       [0.11711712, 0.06896552, 0.19230769, 1.        ],\n",
              "       [0.        , 0.20689655, 0.11538462, 0.84210526],\n",
              "       [0.0990991 , 0.24137931, 0.15384615, 0.78947368],\n",
              "       [0.06306306, 0.10344828, 0.11538462, 0.86842105],\n",
              "       [0.22522523, 0.27586207, 0.5       , 0.5       ],\n",
              "       [0.18018018, 0.44827586, 0.        , 0.10526316],\n",
              "       [0.12612613, 0.27586207, 0.30769231, 0.47368421],\n",
              "       [0.10810811, 0.17241379, 0.07692308, 0.65789474],\n",
              "       [0.09009009, 0.10344828, 0.23076923, 0.68421053],\n",
              "       [0.14414414, 0.13793103, 0.30769231, 0.97368421],\n",
              "       [0.        , 0.        , 0.11538462, 0.44736842],\n",
              "       [0.14414414, 0.24137931, 0.07692308, 0.89473684],\n",
              "       [0.13513514, 0.31034483, 0.42307692, 0.86842105],\n",
              "       [1.        , 1.        , 0.92307692, 0.5       ],\n",
              "       [0.90990991, 0.79310345, 1.        , 0.52631579],\n",
              "       [0.05405405, 0.31034483, 0.19230769, 0.36842105],\n",
              "       [0.18018018, 0.31034483, 0.53846154, 0.63157895],\n",
              "       [0.17117117, 0.13793103, 0.38461538, 0.97368421],\n",
              "       [0.23423423, 0.5862069 , 0.19230769, 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xFGLVl2lSD6",
        "colab": {}
      },
      "source": [
        "#Apply normalization\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y3Sd10_7HXd8"
      },
      "source": [
        "#### 3) KNN (K-Neirest Neighbor Classification) <br> \n",
        "\n",
        "KNN algorithm classifies new examples considering the most represented class among the K nearest neighbors in the hyperspace. This means that if k = 1, the object is simply assigned to the class of the single nearest neighbor. If k = 5, then the classification of the object will be based on the the 5 nearest data points. KNN classifies according to majority vote. It is simple to implement, robust to noisy training data, and effective if training data is large. Nevertheless, we need to determine the value of K and the computation cost is high as it needs to compute the distance of each instance to all the training samples. <br>\n",
        "\n",
        "As seen before we will first need to create our model. We will build the model from the **training set**. So, we will need to split our dataset into **test** and **trainig sets**. Then we use the train set to create the model. Here we need to specify how many neighbors are to be considered in the classification when creating the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F73BSCQVlVx7",
        "colab": {}
      },
      "source": [
        "#Create model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EAKdFLlPmcUF",
        "outputId": "d7cdbebd-57c7-4835-dd01-6bb970192944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Fit model\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c9yJCqcll9lo",
        "outputId": "7ea78b91-0560-45e4-f542-9fccde563aaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Use model on test and check accuracy\n",
        "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
        "     .format(model.score(X_train, y_train)))\n",
        "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
        "     .format(model.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Logistic regression classifier on training set: 0.86\n",
            "Accuracy of Logistic regression classifier on test set: 0.80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBZSIihRKCEg",
        "colab_type": "text"
      },
      "source": [
        "We chose k = 10 arbitrarily, maybe we can have a better accuracy with another number. Let's try for different values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IIGWzoTLAqQ",
        "colab_type": "code",
        "outputId": "e3398c5a-84f9-478a-c041-3fe7d87d9743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "n_neighbors = [2,3,4,5,7]\n",
        "for n in n_neighbors:\n",
        "    model = KNeighborsClassifier(n)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"accuracy for k = \" + str(n) + \" : \" + str(model.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy for k = 2 : 0.8\n",
            "accuracy for k = 3 : 1.0\n",
            "accuracy for k = 4 : 0.9\n",
            "accuracy for k = 5 : 0.9\n",
            "accuracy for k = 7 : 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAKowZm5MY-Z",
        "colab_type": "text"
      },
      "source": [
        "#### 4) Decision Tree <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCjgPfscMomt",
        "colab_type": "text"
      },
      "source": [
        "A decision tree classifier relies on a decision tree to predict the class for a new data point. In fact, it produces a sequence of rules that can be used to classify the data. It is a great algorithm as it can be easily understood and visualized. Also, it can handle numerical and categorical data. It is possible that decision tree build models that are too complexe, that cannot generalize well. It can also be unstable, as small variations in the data set might cause the generation of a completely different tree. <br>\n",
        "\n",
        "Before building it we need to specify the maximum depth of our tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgxIcRa6MbaN",
        "colab_type": "code",
        "outputId": "402deac0-b1c6-4f4b-9902-a9291df1a05f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#create, fit and test model \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(max_depth = 5)\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPn36xwrNWZX",
        "colab_type": "text"
      },
      "source": [
        "We achieve perfection on the test set, but our model may be overly complicated. Let's see if we can reduce max depth without losing accuracy.\n",
        "Let's try randomely some numbers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTpQBh9DzP17",
        "colab_type": "code",
        "outputId": "d3ca1dfc-19ee-48c4-c930-50d2fd85f405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(max_depth = 1)\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtzENTXmNHKH",
        "colab_type": "code",
        "outputId": "54f3b757-a55a-4d93-9f04-64aeff99179e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#fonction to find lowest depth (less complicated model) keeping an accuracy of 1\n",
        "depth = 5\n",
        "model = DecisionTreeClassifier(max_depth = depth)\n",
        "model.fit(X_train, y_train)\n",
        "accuracy = model.score(X_test, y_test)\n",
        "while accuracy == 1:\n",
        "  depth -= 1\n",
        "  model = DecisionTreeClassifier(max_depth = depth)\n",
        "  model.fit(X_train, y_train)\n",
        "  accuracy = model.score(X_test, y_test)\n",
        "print(depth+1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpKrVS1XNqWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}