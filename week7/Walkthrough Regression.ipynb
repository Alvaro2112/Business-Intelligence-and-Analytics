{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "walkthrough_draft.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/Business-Intelligence-and-Analytics/blob/master/week7/Walkthrough%20Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u461z_Wk-K-P"
      },
      "source": [
        "## Walkthrough : Regression\n",
        "\n",
        "Regression is to relate input variables to the output variable, to either predict outputs for new inputs and/or to understand the effect of the input on the output. In prediction, we wish to predict the output for a new input vector. In interpretation, we wish to under- stand the effect of inputs on output.\n",
        "\n",
        "For both the goals, we need to find a function that approximates the output “well enough” given inputs:\n",
        "\n",
        "$$y_n =f(\\boldsymbol{x_{n}})$$\n",
        "\n",
        "In python, a useful library exists to apply regression and other Machine Learning and statisticals tools over the data. It is the so called **sklearn**.\n",
        "\n",
        "This walkthrough will teach you how to use this library in the context of regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Oi8vCkNF_B3P",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "32vbaIBt_5KF"
      },
      "source": [
        "## 1. Load the dataset\n",
        "\n",
        "\n",
        "From this library we import the `LinearRegression` module and the differents datasets used for our examples. In this section, we will discuss the basics of using the linear model with the weather dataset as example. Then you will be given a task and perform your own linear regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FRP6bS5fABwY",
        "outputId": "8bd08095-4312-4f54-d0e6-b730201a898a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "#Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/michalis0/Business-Intelligence-and-Analytics/master/data/weather.csv\"\n",
        "weather = pd.read_csv(url).drop_duplicates().dropna()\n",
        "# Display a sample of the data\n",
        "display(weather.head())\n",
        "#Print the data types\n",
        "print(weather.dtypes)\n",
        "print(\"Data matrix shape: \", weather.shape)\n",
        "# display the columns names\n",
        "print(\"Columns names: \", weather.columns) "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-11-01</td>\n",
              "      <td>Canberra</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>6.3</td>\n",
              "      <td>NW</td>\n",
              "      <td>30.0</td>\n",
              "      <td>SW</td>\n",
              "      <td>NW</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>68</td>\n",
              "      <td>29</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>14.4</td>\n",
              "      <td>23.6</td>\n",
              "      <td>No</td>\n",
              "      <td>3.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-11-02</td>\n",
              "      <td>Canberra</td>\n",
              "      <td>14.0</td>\n",
              "      <td>26.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>9.7</td>\n",
              "      <td>ENE</td>\n",
              "      <td>39.0</td>\n",
              "      <td>E</td>\n",
              "      <td>W</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17</td>\n",
              "      <td>80</td>\n",
              "      <td>36</td>\n",
              "      <td>1012.4</td>\n",
              "      <td>1008.4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>17.5</td>\n",
              "      <td>25.7</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-11-03</td>\n",
              "      <td>Canberra</td>\n",
              "      <td>13.7</td>\n",
              "      <td>23.4</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NW</td>\n",
              "      <td>85.0</td>\n",
              "      <td>N</td>\n",
              "      <td>NNE</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>82</td>\n",
              "      <td>69</td>\n",
              "      <td>1009.5</td>\n",
              "      <td>1007.2</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>15.4</td>\n",
              "      <td>20.2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>39.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-11-04</td>\n",
              "      <td>Canberra</td>\n",
              "      <td>13.3</td>\n",
              "      <td>15.5</td>\n",
              "      <td>39.8</td>\n",
              "      <td>7.2</td>\n",
              "      <td>9.1</td>\n",
              "      <td>NW</td>\n",
              "      <td>54.0</td>\n",
              "      <td>WNW</td>\n",
              "      <td>W</td>\n",
              "      <td>30.0</td>\n",
              "      <td>24</td>\n",
              "      <td>62</td>\n",
              "      <td>56</td>\n",
              "      <td>1005.5</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>13.5</td>\n",
              "      <td>14.1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.8</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-11-05</td>\n",
              "      <td>Canberra</td>\n",
              "      <td>7.6</td>\n",
              "      <td>16.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>10.6</td>\n",
              "      <td>SSE</td>\n",
              "      <td>50.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>ESE</td>\n",
              "      <td>20.0</td>\n",
              "      <td>28</td>\n",
              "      <td>68</td>\n",
              "      <td>49</td>\n",
              "      <td>1018.3</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>11.1</td>\n",
              "      <td>15.4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  Location  MinTemp  ...  RainToday  RISK_MM  RainTomorrow\n",
              "0  2007-11-01  Canberra      8.0  ...         No      3.6           Yes\n",
              "1  2007-11-02  Canberra     14.0  ...        Yes      3.6           Yes\n",
              "2  2007-11-03  Canberra     13.7  ...        Yes     39.8           Yes\n",
              "3  2007-11-04  Canberra     13.3  ...        Yes      2.8           Yes\n",
              "4  2007-11-05  Canberra      7.6  ...        Yes      0.0            No\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Date              object\n",
            "Location          object\n",
            "MinTemp          float64\n",
            "MaxTemp          float64\n",
            "Rainfall         float64\n",
            "Evaporation      float64\n",
            "Sunshine         float64\n",
            "WindGustDir       object\n",
            "WindGustSpeed    float64\n",
            "WindDir9am        object\n",
            "WindDir3pm        object\n",
            "WindSpeed9am     float64\n",
            "WindSpeed3pm       int64\n",
            "Humidity9am        int64\n",
            "Humidity3pm        int64\n",
            "Pressure9am      float64\n",
            "Pressure3pm      float64\n",
            "Cloud9am           int64\n",
            "Cloud3pm           int64\n",
            "Temp9am          float64\n",
            "Temp3pm          float64\n",
            "RainToday         object\n",
            "RISK_MM          float64\n",
            "RainTomorrow      object\n",
            "dtype: object\n",
            "Data matrix shape:  (328, 24)\n",
            "Columns names:  Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',\n",
            "       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n",
            "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
            "       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n",
            "       'Temp3pm', 'RainToday', 'RISK_MM', 'RainTomorrow'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CdrFokUIEDci"
      },
      "source": [
        "**Note:** The purpose here is to predict the temperature from other features (like humidity or pression). It is called multivariate linear regression when we use several features as input, univariate otherwise. We will work with values at **3pm** for simplicity.\n",
        "\n",
        "A LinearRegression has this form for one feature: $$ Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i$$\n",
        "\n",
        "The betas correspond the weights (variables). Combined with the features ( matrix X) we want to predict the target variable (Y vector). The regression will compute the best value of $\\beta_i$.\n",
        "\n",
        "For now we will focus on a simple linear regression with **one feature variable**. We would like to know if we can use the humity to predict the temperature. Let's separate the feature input from the target output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DvHMm6n5Uhef",
        "colab": {}
      },
      "source": [
        "X = weather[['Humidity3pm']] \n",
        "y = weather[['Temp3pm']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KbFaMRiOF-Kr"
      },
      "source": [
        "## 2. Splitting the dataset\n",
        "\n",
        "Sklearn has a very useful module to seprate your dataset in a training and testing set. The training set will be used to retreive the best values of the weights according to a combination of input/output while the test set will be used to evaluate/predict our model. Since our model will be trained on particular values we want to test our data on a new set of data (the test set.\n",
        "\n",
        "The test size here is of 20% of the original data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pa-wOqD6Cei3",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RUoAlVFvLK8a"
      },
      "source": [
        "**Note:** Generally you should normalize the data before splitting the datset. The normalization is important here to reduce the variance of our model and get better results. We skip this step for now.\n",
        "\n",
        "The sklearn code use `MinMaxScaler` module to normalize the data. This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.  \n",
        "\n",
        "This is an example of how to use it:\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(data)\n",
        "#Per feature maximum seen in the data\n",
        "print(scaler.data_max_)\n",
        "# Retur the scale features of X according to feature_range.\n",
        "print(scaler.transform(data))\n",
        "\n",
        "#These two steps can be merged into one shot by:\n",
        "data = scaler.fit_transform(data)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hFz94n5GIP_T"
      },
      "source": [
        "## 3. Create/Fit the model\n",
        "\n",
        "To predict the target variable we will use a simple linear regression. We can import the module like this (already done at the beginning of the file):\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ebSpuUsrG-RF",
        "outputId": "2b3811dc-27a0-4daf-fbf0-d10681e6c310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# There are three steps to model something with sklearn\n",
        "# 1. Set up the model\n",
        "model = LinearRegression()\n",
        "# 2. Use fit\n",
        "model.fit(X_train, y_train)\n",
        "# 3. Check the score/accuracy\n",
        "print(\"R^2 Score of the model: \", round(model.score(X_test, y_test), 3))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 Score of the model:  0.372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qygxTo56HkeH"
      },
      "source": [
        "**Note:** \n",
        "- We create a new LinearRegression model from sklearn\n",
        "- The `fit()` function will fil the linear model from the X_train (features) and the y_train data (target)\n",
        "- The ``score()``function returns the coefficient of determination R^2 of the prediction. he best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
        "\n",
        "After fitting the model, we can easily retreive the values of the different beta coefficients (the intercept, and the weight fro each feature)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WAMS6qKIHC35",
        "outputId": "565754d4-f89a-4ddd-daad-f135e41a173c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Intercept: \", model.intercept_[0]) \n",
        "print(\"Features coefficients (weigths): \", model.coef_.flatten()[0])# Get the coefficients, beta"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intercept:  29.543003059769497\n",
            "Features coefficients (weigths):  -0.22661055784458156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w3_SgE4nsCIp"
      },
      "source": [
        "**Note:** Considering this linear equation: $ Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i$\n",
        "The intercept corresponds to the value of $\\beta_0$ and there is one coefficient,  $\\beta_1$ linked to the humity feature. Since we have only one value for intercept and coefficients represented as arrays, we apply `flattent()` and `[0]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dkdOvMjoI6mQ"
      },
      "source": [
        "## 4. Prediction/Evaluation\n",
        "\n",
        "The model is trained, then we can use the ``predict()`` function to predict the values of the test set using `X_test`. This prediction can be compared to the truth value i.e `y_test`.\n",
        "\n",
        "Here an example for one value prediction. Our model takes a matrix as inputs (X matrix), so even if we want to predict a sclar value we should use `[[...]]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wJm-HPRYtGF6",
        "outputId": "5e6400e2-e044-4a5b-dee9-79da542d372d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Particular value of humidity: \", X_test.iloc[0].values)\n",
        "#Compute the prediction for input 32 (humidity)\n",
        "prediction = model.predict([[32]])\n",
        "print(\"Prediction/Truth for humidity 32: \", prediction, y_test.iloc[0].values)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Particular value of humidity:  [28]\n",
            "Prediction/Truth for humidity 32:  [[22.29146521]] [27.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3CbNbOeB6lE",
        "colab_type": "text"
      },
      "source": [
        "**Note:** Try to use `flatten()` and `[0]` in order to display correctly the above values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uLEovOE8tGyV"
      },
      "source": [
        "## 5. Evaluation and plotting\n",
        "\n",
        "To better understand why the prediction and actual value are different , we can plot the predictions (form a line) and the true values from the test set. It is more interesting to predict from the test set because our model is not trained on these values unlike the train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D1bnZYPnHK8V",
        "colab": {}
      },
      "source": [
        "#Model prediction from X_test\n",
        "predictions = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Asy8tfPuvrKd"
      },
      "source": [
        "We can compare the error of our model by using some metrics like the **MAE (mean absolute error)**, **MSE (mean squared error)** or **R^2** score. Sklearn offers to you some nice modules to compute directly these measures. These modules are imported at the begining of the file.\n",
        "\n",
        "These two metrics takes the `y_true` values and the `predictions` as arguments. Basically it will analyse how much the prediction is far away from the true value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "syKiA49gvpNQ",
        "outputId": "c923230d-17de-4731-8761-1a7012091918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Compare the MAE the MSE and the R^2\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)\n",
        "print(\"R^2 %.2f\" % r2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE 4.27\n",
            "MSE 24.44\n",
            "R^2 0.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3QWBgialsjhv",
        "outputId": "e9d614c7-7240-443a-d57a-2558c6eeb7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plot the prediction (the line) over the true value (the dots)\n",
        "plt.scatter(X_test, y_test)\n",
        "plt.plot(X_test, predictions, 'r')\n",
        "plt.title(\"Humidity against temperature\")\n",
        "plt.xlabel('Humidity')\n",
        "plt.ylabel('Temperature')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZgcVdn38e8vIUAi6LCEPCEQg6As\ngiQQWcQHIaigoEQe5BUVcUVeUQERDagIgoKiIL64AEZAQUQRgsYFkaBiHgUDCTu4kAQIAcIS1hCS\nyf3+UdVMT0/3TM9MV3d11+9zXX1Nd1V1193L3HXOqVPnKCIwM7PiGNHqAMzMrLmc+M3MCsaJ38ys\nYJz4zcwKxonfzKxgnPjNzArGid8aQtKJkn7Yz/pFkt5cz7Z5Iel3kg5vdRxmjebE36HKE23Zsg9K\n+msW+4uIr0XERwe7raRJkkLSWlnENRwR8baIuHg4r1HPZy7pT5Lq+uzyLsvfmDWOE7+Z1aUZB+c8\nFgA6kRN/gaUl7a3KHl8k6bT0/l6SHpT0OUmPSloqabqkt0v6p6QnJJ1Y9tyTJV1S9vgwSYslPS7p\nCxX7Ld/2L+nf5ZKelfSm9LV3KNt+E0nPSxpb5T1sKWlOup/HJF0qqats/U6S5kt6RtIvJF1e9h43\nkDRb0jJJT6b3Nyt77ksl8VJJVtI3020XSnpb2bYflHRfup+Fkt4naVvgB8Du6XtbXiX+rwL/DZyb\nbnNuunwbSdemn8W9kg6p+J6+lzZFPStprqT/kvTtNLZ7JE0p236RpBMk3ZWuv1DSumXrD5C0QNJy\nSf8r6XUVz/28pNuA5yStJWmGpP+k7/UuSe9Kt636fitrNJW1gvR3eJSkfwH/GigmGz4nfuvPfwHr\nAhOAk4ALgPcDO5Mkqy9J2qLySZK2A74PHAZsCmwEbFa5XWrP9G9XRKwXEX8Gfpbup+RQ4LqIWFbl\n+QJOT/ezLbA5cHIax9rAVcBFwIbAZcC7yp47ArgQeCUwEVgBnFsjToBdgXuBjYFvADOVeBnwHeBt\nEbE+8AZgQUTcDRwJ/C19b12VLxgRXwBuAD6ZbvPJ9PWuBX4KbAK8B/he+rmWHAJ8MY1lJfA34Jb0\n8RXAWRW7eh+wL7Al8Jr0uaQHiB8BHyf5ns4DfiVpnbLnHgrsT/IdrQb+Q/L9vwI4BbhE0vh63m8/\nppN8vtvVGZMNgxN/Z5uVlpiWp6Wv7w3y+auAr0bEKpJkvDFwTkQ8ExF3AncBO1Z53sHA7Ij4S0Ss\nBL4ErBnEfi8GDpWk9PFhwE+qbRgR/46IayNiZXpgOAt4U7p6N2At4DsRsSoirgRuKnvu4xHxy4h4\nPiKeAb5a9txqFkfEBRHRncY4HhiXrlsDbC9pdEQsTT+foToAWBQRF0bE6oiYD/wSeHfZNldFxM0R\n8QLJwe2FiPhxGtvlwJSK1zw3Ih6IiCfS93louvwI4LyIuDEiutNzGitJPruS76TPXQEQEb+IiIci\nYk1EXE5SSt9lGO8X4PSIeCLdRz0x2TA48Xe26RHRVboBnxjk8x9PEwkkpWGAR8rWrwDWq/K8TYEH\nSg8i4jng8Xp3GhE3As8De0naBtgK+FW1bSWNk/QzSUskPQ1cQnKAKsWxJHqPRPhA2XPHSDovbZJ6\nmqTZqUvSyBqhPVwW4/Pp3fXS9/d/SEq7SyX9Jo17qF4J7Fpx0H4fSQ2spPJ7GOh7eaDs/mKSz6a0\nr+Mq9rV52frK5yLpA2XNMMuB7en5zIeqfB/1xGTD4MRfbM8DY8oe/1etDQdpKck/KpAkWJIqezW1\nhoe9mKS55zDgirRkW83X0tfYISJenj6nVFNYCkwoqzlQHhdwHLA1sGv63FKzU/n2dYmIayLiLSS1\ngHtImsWg9vvr9fSKxw8Afy4/aKdNJ/93sHGVKX/fE4GHyvb11Yp9jYmIy6rFJ+mVJO/tk8BGaYHi\nDno+s2rv9zkG/p1VHpwHismGwYm/2BYA75U0UtJ+9N/MMRhXAAdIemPazv4Vav/WlpE0k7yqYvkl\nJO3x7wd+3M++1geeBZ6SNAE4vmzd34Bu4JPpSckD6d0ksT5J6Xi5pA2BL9fz5iqltY4D07b5lWk8\npaatR4DN0s+hlkfo/f5nA69RcoJ8VHp7fXrydKiOkrRZ+j6/QNIcBEkSP1LSrqXzFZL2l7R+jdd5\nGUmSXgYg6UMkJf7y91L5fhcAB6U1rK2AjwwQ62BjskFy4i+2o4F3AKWmhFmNeNG0ffsokpOTS4En\ngQdrbPs8SZvz3LRav1u6/AGSk5VBcvKzllOAnYCngN8AV5a99ovAQSSJZjnJQWQ2SXIG+DYwGngM\n+Dvw+8G/WyD5P/oMSSn6CZIDaKl0Pge4E3hY0mM1nn8OcHDa4+Y76fmGt5Kc1H2IpInp68BwTm7+\nFPgDcB/JydnTACJiHvAxkpPaTwL/Bj5Y60Ui4i7gWyQH1UeAHYC5ZZtUe79nAy+m218MXNpfoION\nyQZPnojF8krSj4CHIuKLDXzNG4EfRMSFjXrNvJO0CPhoRPyx1bFYPvhiCcslSZNISuuVvVMG+zpv\nIumC+RhJreZ1DL1kb9YR3NRjuSPpVJIThmdGxMJhvtzWwK0kTT3HAQdHxNJhvqZZW3NTj5lZwbjE\nb2ZWMG3Rxr/xxhvHpEmTWh2GmVlbufnmmx+LiD5jXLVF4p80aRLz5s1rdRhmZm1F0uJqyzNr6pG0\nrqSbJN0q6U5Jp6TLL1IyeuGC9DY5qxjMzKyvLEv8K4FpEfGspFHAXyX9Ll13fERckeG+zcyshswS\nfzow1rPpw1HpzV2IzMxaLNNePekYMAuAR4Fr01EXAb4q6TZJZ9caY1vSEZLmSZq3bFm1YdjNzGwo\nMk386Vjak0km4dhF0vbACcA2wOtJJsf4fI3nnh8RUyNi6tixfU5Km5nZEDWlV09ELJd0PbBfRHwz\nXbxS0oXAZ7PY56z5Szjzmnt5aPkKNu0azfH7bs30KROy2JWZWVvJslfPWKVzn0oaDbwFuEfS+HSZ\nSKZbu6PR+541fwknXHk7S5avIIAly1dwwpW3M2v+kkbvysys7WTZ1DMeuF7JJM3/IGnjnw1cKul2\n4HaSWXtOa/SOz7zmXlas6u61bMWqbs685t5G78rMrO1k2avnNqqMrBgR07LaZ8lDy1cMarmZWZF0\n5Fg9m3aNHtRyM7Mi6cjEf/y+WzN6VO/5skePGsnx+27doojMzPKjLcbqGaxS7x336jEz66sjEz8k\nyd+J3sysr45s6jEzs9qc+M3MCsaJ38ysYJz4zcwKxonfzKxgnPjNzArGid/MrGA6th//QDxss5kV\nVSETf2nY5tIInqVhmwEnfzPreIVM/P0N29xJid+1GjOrppCJvwjDNrtWY2a1FPLkbhGGbfZkNGZW\nSyETfxGGbS5CrcbMhqaQiX/6lAmcftAOTOgajYAJXaM5/aAdOqoJpAi1GjMbmkK28UPnD9t8/L5b\n92rjh86r1ZjZ0BQ28Xc6T0ZjZrU48XewTq/VmNnQOPHX4D7wZtapnPircB94M+tkhezVMxD3gTez\nTubEX4X7wJtZJ3Pir8J94M2sk2WW+CWtK+kmSbdKulPSKenyLSTdKOnfki6XtHZWMQxVEa7sNbPi\nyrLEvxKYFhE7ApOB/STtBnwdODsitgKeBD6SYQxDUoQre82suDLr1RMRATybPhyV3gKYBrw3XX4x\ncDLw/aziGCr3gTezTpVpG7+kkZIWAI8C1wL/AZZHxOp0kweBqtlV0hGS5kmat2zZsizDNDMrlEwT\nf0R0R8RkYDNgF2CbQTz3/IiYGhFTx44dm1mMZmZF05RePRGxHLge2B3oklRqYtoMWNKMGMzMLJFl\nr56xkrrS+6OBtwB3kxwADk43Oxy4OqsYzMysryyHbBgPXCxpJMkB5ucRMVvSXcDPJJ0GzAdmZhiD\nmZlVyLJXz23AlCrL7yNp7881D9JmZp3Kg7RV4UHazKyTOfFX0d8gbYNJ/K41mFkeOfFX0YhB2lxr\nMLO88iBtVTRikDYP7WxmeeXEX0UjBmnz0M5mlldu6qmiEROVb9o1miVVkryHdu7N50HMms+Jv4bh\nDtJ2/L5b92rjBw/tXMnnQcxaw009GfHQzgPzeRCz1nCJP0Me2rl/Pg9i1hpO/DnW6e3fPg9i1hpu\n6smpUvv3kuUrCHrav2fN75zBTD3FpVlruMSfI+Ul/BES3RG91g/l6uE8a0TvKTMbPCf+Jqpsutl7\nm7Fcf88yHlq+gleMHsVzL65mVXeS7CuTfkmntX/7PIhZ8znxN0m1rouX/P3+l9YvX7GqrtfJU/t3\np5+DMOtUTvxNUq3r4mDlqf3bffDN2pdP7jbJUJtoRkq5vA7AffDN2pdL/E1Sq+tif0aPGpmrZF/O\nffDN2pdL/E1SretipVEjxAZjRuWyhF+pESOYmllruMTfJNW6Lpb36mm3k6Mei8isfTnxN1EndV10\nH3yz9uXEb0PWSQcysyJxG7+ZWcE48ZuZFYwTv5lZwXR24l+yBE4+GR57rNWRmJnlRmaJX9Lmkq6X\ndJekOyUdnS4/WdISSQvS29uzioGrroJTToGxY0GC738fagx+ZmZWFFmW+FcDx0XEdsBuwFGStkvX\nnR0Rk9PbbzOL4BOfSBJ/+eMRI+BVr4J7PbSAmRVTZok/IpZGxC3p/WeAu4Hm9v0bMQJOOikp5S9e\nDJMnJ8sXLoRttklqAa99LazwMANmVhxNaeOXNAmYAtyYLvqkpNsk/UjSBs2IgYkTYf785CBwySU9\ny++6C8aMSQ4CX/5yU0IxM2slRcZt3pLWA/4MfDUirpQ0DngMCOBUYHxEfLjK844AjgCYOHHizosX\nL258cMuXwwY1jjuLFsErX9n4fZqZNYmkmyNiauXyTEv8kkYBvwQujYgrASLikYjojog1wAXALtWe\nGxHnR8TUiJg6duzYbALs6kpqABFw+um9102alNQCpGz2bWbWIln26hEwE7g7Is4qWz6+bLN3AXdk\nFcOgzJiRHABeeKHvutIB4P3vb35cwzBr/hL2OGMOW8z4DXucMaejJmo3s6HLssS/B3AYMK2i6+Y3\nJN0u6TZgb+DYDGMYvHXW6akFzJ7de92ll/YcBJ5+ujXx1ak0Q9aS5SsIembIcvI3s7ra+CW9Enh1\nRPxR0mhgrbSnTlNMnTo15s2b16zdVddfk08Orw3Y44w5VSd+GSmxJiK3o2l6Hl+zxhlyG7+kjwFX\nAOelizYDZjU2vDZQqgVccUXfdaVawA03ND+uGmrNhNUdkdsagGspZs1RT1PPUSTNNk8DRMS/gE2y\nDCrX/ud/eg4Clfbcs6knhPtrw69nJqy8zZHreXzNmqOexL8yIl4sPZC0FklXTCsdAB58sO+60gHg\nuOMy2fVApeN6pnqEfM2R63l8q/NJemu0ehL/nyWdCIyW9BbgF8Cvsw2rzUyY0HMQeP3re68766ye\ng0ADrxAeqHQ8fcoETj9oByZ0jUYkbfvV5GmOXM/j25ebvywL9ST+zwPLgNuBjwO/Bb6YZVBt7aab\nkgNAd3ffdaUrhBvQFFRP6Xj6lAnMnTGNhWfsz7cO2bFPDSBvc+RWq6XkLcZmc/OXZaHfxC9pJEk/\n/Asi4t0RcXB63009AxkxoqcWcOqpfdeXDgA33th3XR0GWzqurAFM6BrN6QftkKseM+0QY7O5+cuy\nMGB3TklXA5+KiPubE1JfuejO2SgN6hZaagIoLw2OHjWy8Imy09TqljuhazRzZ0xrQUTWToYzZMMG\nwJ2SrpP0q9Kt8SEWRKkWcNttfdeVagF77jngy7h0XAxu/rIs1FPif1O15RHx50wiqqKjSvzV9FcL\nePFFGDWqebFY7viiNhuqWiX+tQZ6YjMTfGGlB9+rb1rIgbu+qve6tdfus12ROOkltbuivWfLVj1X\n7j4j6en09oKkbkn5HqimDc2av4QZv76XSZ+fzaTPz+aejasMCV1qCvrDH5ofYAvksSuj+9RbJ6in\nxL9+6X464uaBJFMpWgNVdtvb7yPfBdKTeCfs03vjffftud/BtYD+ujK2ogRceUK9dCACXCK3tjKo\n0TkjMQvYd8CNbVD67bZXOiH83e/23aBUC+jqGnYMeSvN5q0ro/vUW6cYsMQv6aCyhyOAqUCVQett\nODbtGl21216vfvmf+ERyg74nhJ96qmdZd3dyHcEg5LE0W9dn0kR5OxCZDVU92eEdZbd9gWdImnus\ngQbdba9UC3j44b7rRo4c9BXCeSzN5q0ro4eUsE4xYIkf+GFEzC1fIGkP4NFsQiqmUql60D1Yxo3r\naeevluhLy+bMgb33rvkyeSzNDvkzycjx+25d9aK58gOReyFZO6inH/8tEbHTQMuy1PH9+LMwyCuE\nfYVoffpL7L6a2vJm0P34Je0OvAEYK+kzZateDgw83q+1Vim577NPUtovVzoobLEF3HcfUF9p1vrv\nU5+3XkhmtfTX1LM2sF66zfply58GDs4yKGug667ruV9ZC1i48KVl09MDhZsp+tdfiT+PzWVm1dRM\n/OkVu3+WdFFELG5iTJaVUi1gwQKYMqX3OonpwPTy7ayXgXo+5a0Xklkt9fTqeV7SmZJ+K2lO6ZZ5\nZJadyZNrTx8JPT2C7ryzuXHl3EA9n/LWC8mslnoS/6XAPcAWwCnAIuAfGcZkzVQ6AFQ7CGy/fVPn\nEM67gZpyPGKqtYt6unNuFBEzJR1d1vzjxN+J6ukW+uY3w7XXNi+mHKmnKccDqlk7qKfEvyr9u1TS\n/pKmABtmGJO1Wn+1gD/+sbC1ADflWKeoJ/GfJukVwHHAZ4EfAsdmGpXlR+kAMGtW33WlA0BBDgJu\nyrFO0e8FXOmcu5+OiLObF1JfvoBraDK7irS/RP/ww8nVxGbWcrUu4Krnyt2bImKXIexwc+DHwDgg\ngPMj4hxJGwKXA5NIThQfEhFP9vdaTvyDV+0q0lEjxHrrrsXy51c15kCwenX/s4O5W6hZSw1nzt25\nks6V9N+Sdird6njeauC4iNiOZPz+oyRtB8wArouIVwPXpY+twap1PVy1Jnjy+VWNm9RkrbXq6xZ6\n5JFD34eZNVw9iX8y8FrgK8C30ts3B3pSRCyNiFvS+88AdwMTSEb2vDjd7GLSa4asseq5WrSho2/2\nd0L4vPMKdS7ALO/qmYGr9pCOdZI0CZgC3AiMi4il6aqHSZqCqj3nCOAIgIkTJw43hMKp1fWwUibD\nCZSS/+mnw4kn9l5XnvzdFGTWEvXMuTtO0kxJv0sfbyfpI/XuQNJ6wC+BYyKi11y9kZxgqPrfHxHn\nR8TUiJg6duzYendnqWpdD6vJdDiBE06orynoueeGvIu8zRpm1g7qaeq5CLgG2DR9/E/gmHpeXNIo\nkqR/aURcmS5+RNL4dP14PK5/Jiq7HnaNHsWokb2bWpraB710AHjqqb7r1ltvSE1BeZyM3awd1JP4\nN46InwNrACJiNdDd/1Nemph9JnB3RJxVtupXwOHp/cOBqwcVsdVt+pQJzJ0xjYVn7M+CL7+VMw/e\nsfV90F/+8vpqAaeeOuBL5XHWMLN2UM+QDc9J2oi0SUbSbkCVYlsfewCHAbdLWpAuOxE4A/h52ly0\nGDhk0FHbkORuOIHy5F9Z2j/ppORWuV0ZD4Oc8KxfNlj1JP7PkJTSt5Q0FxhLHePxR8RfgVp1933q\njrBF/M/UZKXkvueecMMNvdfVOCFc6wT2CIktZvymEN/bQENFm1UzYFNP2iXzTSSzcX0ceG1E3JZ1\nYK3ktuMW+stf6msKWrOm5gns7oia31unnQx2c5cNxYAlfknrAp8A3kjS3HODpB9ExAtZB9cqnTKF\nXtvXWkrJf9GiZJrIciNHvjRxzB6nX8dDy1cwQqK74oBR/r21onSc9Xfg5i4binpO7v6Y5AKu/wec\nm97/SZZBtVon/DN1VK1l0qR+awFzT9iHhV8/gP3uvqHq+tL31uzScTO+g1rdcT3rl/WnnsS/fUR8\nJCKuT28fI0n+HasT/pk6tgmgnyuEv3v1GSz6+gEs+voBvZaXvrdmH9Cb8R3kYajoTms+K4J6Tu7e\nImm3iPg7gKRdgY4eMe34fbfuM8BZK8ZdH6iZoPATf5eS/0YbwRNP9FpVnvxn3fIgUN9EKo3UjO+g\n9H23qknPJ5fbUz2Jf2fgfyXdnz6eCNwr6XaSi29fl1l0LdLqfyYY+B/KE3+XefzxnvtVLgKbvtNm\nABx/y4NNPaA36ztoZTfdTjkfVjT1JP79Mo8ih1rd532gf6iB1uel1tJ0pVrA3/8Ou+/ea9X0nTZ7\naUTALT4/O/MDehG+g0LULDtQPYO0LZa0AbB5+falkTctGwP9Q9Uz8Te0ttbSCr2av06/LnnPaYm/\n3MJSU9ABt5MMGtt4RfgOClWz7CD1dOc8Ffgg8B96BlQLYFp2YdlA/1Ce+Luvms1ftzzY8zlUNgXt\nsEPP/QxGC+3076AItZpOVE+vnkOALSNir4jYO7056WdsoN4ajejN0Wm9MerqRVPqETSiyk+/dHHY\nPrm/sDw3PA9xe6qnjf8OoAuPotlUAzUTDLcZoV17YzSsJ1N32QGishYwZ07PMs8ZMKBOr9V0onoS\n/+nAfEl3ACtLCyPinZlFZcDA/1DD+Ydrx94YmfVkKiX3X/8a3lnxs/bEMdaB6mnquRj4Osmomt8q\nu1kba8feGAM15Qy7+esd76hvnKBHXfm19lZPif/5iPhO5pFYU7Vjb4ym9mQqJf/u7mRS+XLjxvXd\nzpqq7ceharF6Ev8Nkk4nGZq5vKnH3TnbWDv2xmhJT6aRI3uSe7UZwkrLzjwTPvvZxu3XamrX81N5\nohigxCLp+iqLo5k9e6ZOnRrz5nX0KBENMdhSUDNKTY3cx6z5Szj+F7eyak3Pb3bUCHHmu3cc1Ent\nhsTT3zSRrgVkao8z5lQtAEzoGs3cGZ3T4bARv1VJN0fE1Mrl9VzAtfeg9mQtMZRSUNa9MTIpmVXm\n20FM09vQeErJ/bLL4L3vrYgpDWrddWFFfs+ZtKt2PD81WFnXagY8uStpnKSZkn6XPt4unTbRcqTW\nic/jfn5ry/rpN3p0yjOvuZdV3b1L06u6o+7Xy2S0zEMPrX1C+IUXek4Ir1zZd70NSSeMnjuQrEd2\nradXz0XANcCm6eN/Asc0ZO/WMLVKO/3NRtWqmIZaMhvu62VeUiwdAJ5/vu+6ddftOQjYsORhKOqs\nZf1brZn4JZWagTaOiJ8DawAiYjXQXet51hr1lHaaPR5/o0tmw329ppUUR4+ur1von/7U2P0WRBGu\nFs76t9pfif+m9O9zkjYiHadH0m7AUw3ZuzVMrflnKzWzHbTRJbPhvt6kjar/09Ra3hD9TBzD3nu7\nFjBE06dMYO6MaSw8Y3/mzpjWUUkfsq/V9Jf4S7/Gz5B05dxS0lySqRg/1ZC9W8NUloJG1kgmzWwH\nbXTJbLiv9/f7nhzU8oYrHQB+/OO+60oHgOnT+66zwsm6VlOzO6ekB4Gz0ocjgHVIDgYrge6IOKvq\nEzPg7pyDV9krAJISQ6dViQdj0ozf1Fy36Iz9G7KPQXfB66+0391dfTA5szoNpTvnSGA9+naYG9PI\nwCwbRRgLfrBGSnRXKejUqh0N1pC64JXiWb4cNtigIrCRfbcza4D+Ev/SiPhK0yKxhvOoib0duuvm\nXPL3+6sub4RhDXzX1VXfFcL33guveU0DorUiq6eNf0gk/UjSo+monqVlJ0taImlBenv7cPZhNhin\nTd+B9+828aUS/kiJ9+82kdOm7zDAM+vTsC54/Z0Q3nprnxC2YeuvxD/c2SguAs4lORlc7uyI+OYw\nX9s6RLMH2zpt+g4NS/SVMhn4rpT8zz8fPv7x3utKyf8rX4EvfWno+7DCqVnij4gnhvPCEfEXYFiv\nYZ2t1Ca+ZPmKll1k1kiZdsE74ojatYCTTnItwAalFV0GPinptrQpaIOBN7dOlfVl6c3WjAuLZs1f\nwrZf/B2TPj+b1x/VT7fQsWMbtk/rPAOOzjmsF5cmAbMjYvv08TjgMZKLwU4FxkfEh2s89wjgCICJ\nEyfuvHjx4szitMYZTNPNFjN+Q7Vfn4CFDepe2WlqjUx519kHM+bFF6o/6dFHfSAoqFrdOZta4o+I\nRyKiOyLWABcAu/Sz7fkRMTUipo7N6Y+20yYrH67BNt0UYbCtRqt1ovi1x15Ruylok03cFGS9NDXx\nSxpf9vBdJBO5t6VOa59uhME23RRhsK1Gq+tgWToAnFXlGsvSAeDyyzOK0NpBZolf0mXA34CtJT2Y\nDuX8DUm3S7oN2Bs4Nqv9Z63T2qcbYbDdGYsw2FajDepgeeyxtWsB73mPawEFVs/Ui0MSEYdWWTwz\nq/01WxEmgxisoXRn9EVmA6s8b/I/O0/g+nuWDa4LbCn5/+c/sNVWvdeVkv8ee8Bf/9r4N2C5k1ni\n73TtOFl51tpxHt+8qzYMxC9vXjL0mtGWW9a+Qnju3J5lzz0HYzw6S6fyCFBD5Pbpvtx003iZNimW\nmoG6q0yv8bKXuSmog7nEP0QeBK06N900VlOaFEeM6KkFnHEGnHBC7/Wl5D93LrzhDY3br7VMpv34\nG8XDMluzNHsIiYHU6rc/oWs0c2dMy3bn/ZX22yBvWE768ZvlWR676La0SbHUFHRHlV7XpWagYzz9\ndjty4jdL5bGLbi7Om7z2tbW7hZ5zTs9BYNWq5sVkw+I2frNUXrvoZn3eZFDNW6Xkv2oVrL1273Wl\nxxMngodYyTWX+M1SRRxCYsjNW6NG9dQCjj6697r77++pBTz4YGax29A58Vuh9De+UhG76Dakeevb\n367dFLT55m3ZLbTTx+Fy4rfCGKh0m4v29CZrePNW6QAwf37fdaUDwNVXD+21mySPJ/kbzW381lSt\n7C5Zz5y4RbsOIbMr0CdP7qkB7LRT7wPB9Ok999esyV1tYFhzJ7cJl/itaRpRkhpOFTyvJ29bqSnN\nW7fckhwEXqgyX8CIEUni/+hHG7e/YSrC78SJ35pmuO3Jwz1w5OXkbZ7aj5vavLXOOj1NQd+smHZ7\n5syepqDHHmv8vgchL7+TLDnxW9MMtyQ13ANHHk7e5rH9ePqUCcydMY2FZ+zP3BnTmtOccdxxtU8I\njx3b0hPCefidZM2J35pmuOcLs0YAAAwISURBVCWp4R448nDyNo8XibVc6QBQbViW0gHgT39qWjh5\n+J1kzSd3rWmGO2xzI05EtvrkbRHaj4ds5517agDjx8PDD/es23vvnvtNGCeo1b+TrLnEb00z3JJU\nJ1TBi9B+3BBLlyYJ/pln+q4r1QLOP7/5cXUIj85pbSVvo2cOVuXEKpAcvDqtKSETF1wARxxRfd3K\nlX2HkLCao3M68Zs1WbsfvHKh1onfb3wDjj++ubHkmBO/mXWeRYtgiy2qr1uyBDbdtKnh5I3H4zez\nzjNpUk+voC9+sfe6CROSmsE739mS0PLMJX5ra242sT6efz6ZM7iagk0f6RK/dZw8XgxlOTBmTE8t\nYNas3uv22COpBay9Nqxe3Zr4csCJ39pWHi6GytPwC1bFgQcmB4A1a2D77XuWr1qVzCkgwXnntS6+\nFnHit7bV6ouhXONoIxLcfntyELj77t7rjjwyN+MENYsTv7WtVl8MlYcahw3BNtv0NAV9+tO915XG\nCfrAB1oTW5Nklvgl/UjSo5LuKFu2oaRrJf0r/btBVvu3znf8vlszamTv/tyjRqppV/K2usZhDXDO\nOckB4Kmnei//yU96agFLl7YmtgxlWeK/CNivYtkM4LqIeDVwXfrYbOgqO6U1sZNaq2sc1kAvf3lP\nLeDSS3uv23TT5ABw5plNGSeoGTJL/BHxF+CJisUHAhen9y8GpmM2RGdecy+r1vT+R1y1JprW1NIJ\nYwdZFe99b88J4fJ5Az73uWTimHHj4LbbWhdfAzS7jX9cRJTqTQ8D42ptKOkISfMkzVu2bFlzorO2\n0uqmliIM31toUs+8AQ89lHQFBXj0Udhxx2T9xz9efWaxnMv0Ai5Jk4DZEbF9+nh5RHSVrX8yIgZs\n5/cFXFbNHmfMqTpM84Su0cydMa0FEVkhXHUVHHRQ3+W//S287W3Nj6cfebmA6xFJ49OAxgOPNnn/\n1kHc1GIt8a53JbWA556DD36wZ/nb357UAvbZB3LeStHsxP8r4PD0/uHA1U3ev3WQTmlq8UVgbWrM\nGLjwwuQg8I9/JCeIAebMgU02SQ4C3/1uLk8IZ9bUI+kyYC9gY+AR4MvALODnwERgMXBIRFSeAO7D\nTT3WqTw+f4dZswa+9jX40pd6L584Ea65JrmGoIma3tQTEYdGxPiIGBURm0XEzIh4PCL2iYhXR8Sb\n60n6Zp3MF4F1mBEjklFCI+D++2GnnZLl998P226b1AKOOQZefLG1YbZ072YF1+qeSZahzTeHm29O\nDgI//WnP8nPOgXXWSQ4Cc+a0JDQnfrMW8kVgBXHoockB4Omn4ZBDepbvs09yAHjHO+DJJ5sWjhO/\nWQu5Z1LBrL8+XH55chCYO7dnnuDZs2HDDZODwMyZmYfhxG/WQp3SM8mG4A1vSCaJX70aTjyxZ/lH\nP5ocALbdFu67L5NdewYuM2soz4o2DPfdlzT73HVXz7LFi5NeQUNQq1fPWkMO0MysQmX31NIcBYCT\nfz1e9Sq4887k/o9+BPPmJWMDNZibesysYdw9tYE+/GH43veSHkAN5sRvZg3j7qntwYnfzBrG3VPb\ngxO/mTWMu6e2B5/cNbOGKZ3Ada+efHPiN7OGmj5lghN9zrmpx8ysYJz4zcwKxonfzKxgnPjNzArG\nid/MrGCc+M3MCsaJ38ysYJz4zcwKxonfzKxgfOWumeWeJ3dpLCd+M8s1T+7SeG7qMbNc8+QujefE\nb2a55sldGs+J38xyzZO7NF5LEr+kRZJul7RA0rxWxGBm7cGTuzReK0/u7h0Rj7Vw/2bWBjy5S+O5\nV4+Z5Z4nd2msVrXxB/AHSTdLOqLaBpKOkDRP0rxly5Y1OTwzs87VqsT/xojYCXgbcJSkPSs3iIjz\nI2JqREwdO3Zs8yM0M+tQLUn8EbEk/fsocBWwSyviMDMroqYnfkkvk7R+6T7wVuCOZsdhZlZUrTi5\nOw64SlJp/z+NiN+3IA4zs0JSRLQ6hgFJWgYszujlNwby3q007zHmPT5wjI2Q9/gg/zE2O75XRkSf\nk6RtkfizJGleRExtdRz9yXuMeY8PHGMj5D0+yH+MeYnPQzaYmRWME7+ZWcE48cP5rQ6gDnmPMe/x\ngWNshLzHB/mPMRfxFb6N38ysaFziNzMrGCd+M7OCKVTil7S5pOsl3SXpTklHp8s3lHStpH+lfzdo\nUXzrSrpJ0q1pfKeky7eQdKOkf0u6XNLarYivItaRkuZLmp3HGKvN+ZCX7zmNpUvSFZLukXS3pN1z\nFt/W6WdXuj0t6ZicxXhs+n9yh6TL0v+fvP0Oj07ju1PSMemyln+GhUr8wGrguIjYDtiNZIC47YAZ\nwHUR8WrguvRxK6wEpkXEjsBkYD9JuwFfB86OiK2AJ4GPtCi+ckcDd5c9zmOMe0fE5LJ+03n5ngHO\nAX4fEdsAO5J8lrmJLyLuTT+7ycDOwPMk42rlIkZJE4BPA1MjYntgJPAecvQ7lLQ98DGSsch2BA6Q\ntBV5+AwjorA34GrgLcC9wPh02Xjg3hzENga4BdiV5Eq/tdLluwPXtDi2zUh+sNOA2YByGOMiYOOK\nZbn4noFXAAtJO1fkLb4q8b4VmJunGIEJwAPAhiRDv8wG9s3T7xB4NzCz7PGXgM/l4TMsWon/JZIm\nAVOAG4FxEbE0XfUwyXhCLZE2oSwAHgWuBf4DLI+I1ekmD5L86Fvp2yQ/4DXp443IX4zV5nzIy/e8\nBbAMuDBtLvthOmBhXuKr9B7gsvR+LmKMZITfbwL3A0uBp4Cbydfv8A7gvyVtJGkM8HZgc3LwGRYy\n8UtaD/glcExEPF2+LpLDcMv6uEZEdyTV681IqojbtCqWaiQdADwaETe3OpYB9DvnQ4u/57WAnYDv\nR8QU4Dkqqvut/h2WpG3k7wR+UbmulTGm7eIHkhxENwVeBuzXilhqiYi7SZqe/gD8HlgAdFds05LP\nsHCJX9IokqR/aURcmS5+RNL4dP14ktJ2S0XEcuB6kupql6TSSKqbAUtaFhjsAbxT0iLgZyTNPeeQ\nrxhLJUKi95wPefmeHwQejIgb08dXkBwI8hJfubcBt0TEI+njvMT4ZmBhRCyLiFXAlSS/zbz9DmdG\nxM4RsSfJOYd/koPPsFCJX8lY0DOBuyPirLJVvwIOT+8fTtL233SSxkrqSu+PJjn/cDfJAeDgVscH\nEBEnRMRmETGJpAlgTkS8jxzFqNpzPuTie46Ih4EHJG2dLtoHuIucxFfhUHqaeSA/Md4P7CZpTPp/\nXfoMc/M7BJC0Sfp3InAQ8FPy8Bm26sRHK27AG0mqVbeRVLsWkLS7bURysvJfwB+BDVsU3+uA+Wl8\ndwAnpctfBdwE/Jukyr1Oqz/LNK69gNl5izGN5db0difwhXR5Lr7nNJbJwLz0u54FbJCn+NIYXwY8\nDryibFluYgROAe5J/1d+AqyTp99hGuMNJAekW4F98vIZesgGM7OCKVRTj5mZOfGbmRWOE7+ZWcE4\n8ZuZFYwTv5lZwTjxW2FIerbi8Qclndug1z5S0geqLJ8k6Y70/lRJ30nv7yXpDY3Yt9lgrTXwJmY2\nkIj4QR3bzCPpuw/JNRDPAv+bYVhmVbnEbwZIukjSwWWPn03/7iXpz5KulnSfpDMkvU/JvAm3S9oy\n3e5kSZ9N7++sZE6FW4Gjyl5zL0mz0wECjwSOTce6/29JC9PhRJD08vLHZo3mxG9FMrp8chHgK3U+\nb0eSRL0tcBjwmojYBfgh8Kkq218IfCqSeRX6iIhFwA9Ixo2fHBE3AH8C9k83eQ9wZSRj0Jg1nBO/\nFcmKNNGWJhg5qc7n/SMilkbESpJhsv+QLr8dmFS+YTrWUldE/CVd9JM69/FD4EPp/Q+RHDzMMuHE\nb5ZYTfr/IGkEUD5l38qy+2vKHq+hQefJImIuMEnSXsDIiLijEa9rVo0Tv1liEckUg5CMPz+k9vVI\nhtNeLumN6aL31dj0GWD9imU/Jhm90aV9y5QTv1niAuBN6QnZ3UkmRxmqDwHfTc8jqMY2vwbeVTq5\nmy67lGSUzstqPMesITw6p1lOpL2KDoyIw1odi3U29+M3ywFJ/49ktqu3tzoW63wu8ZuZFYzb+M3M\nCsaJ38ysYJz4zcwKxonfzKxgnPjNzArm/wPebACwhMeRyAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oL9jvHvRJnpR"
      },
      "source": [
        "## 6. Multivariate variables\n",
        "\n",
        "Now we will apply the same piece of code to several features. For instance it should be interesting to use: humidity, pressure, sunshine and cloud data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ViJclqSnJUsx",
        "outputId": "5d8067e1-e7b8-439f-a390-3d416e9a8682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# 1. Split the data by features and target\n",
        "X = weather[['Humidity3pm', 'Cloud3pm', 'Pressure3pm', 'Sunshine']] \n",
        "y = weather[['Temp3pm']]\n",
        "# 2. Split the data into a training a test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\n",
        "# 3. Set up the model\n",
        "model = LinearRegression()\n",
        "# 4. Use fit\n",
        "model.fit(X_train, y_train)\n",
        "# 5. Print the coefficients of the linear model\n",
        "print(\"Intercept: \", model.intercept_) \n",
        "print(\"Features coefficients (weigths): \", model.coef_)# Get the coefficients, beta\n",
        "\n",
        "# 6.Prediction\n",
        "print(\"Particular value of ['Humidity3pm', 'Cloud3pm', 'Pressure3pm', 'Sunshine']: \", X_test.iloc[0].values)\n",
        "pred = model.predict([[ 28.0, 7.0, 1018.2, 7.3]])\n",
        "print(\"Prediction/Truth for [ 28.0, 7.0, 1018.2, 7.3]: \", pred, y_test.iloc[0].values)\n",
        "# 7. Evaluate the model over the test set\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)\n",
        "print(\"R^2 %.2f\" % r2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intercept:  [361.96448369]\n",
            "Features coefficients (weigths):  [[-0.20850482  0.53595273 -0.33294024  0.39432442]]\n",
            "Particular value of ['Humidity3pm', 'Cloud3pm', 'Pressure3pm', 'Sunshine']:  [  28.     7.  1018.2    7.3]\n",
            "Prediction/Truth for [ 28.0, 7.0, 1018.2, 7.3]:  [[23.75683013]] [27.]\n",
            "MAE 3.90\n",
            "MSE 21.85\n",
            "R^2 0.44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RT2cXh_mzasf",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}