{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Exercise 1 .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/Business-Intelligence-and-Analytics/blob/master/week2%20-%20Pandas%20and%20Python/Pandas/Exercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILyU0L16vFm6",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C3A0jwrvFm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhPJiZDYvFnK",
        "colab_type": "text"
      },
      "source": [
        "1) We will work on one datasets that contains 2 files. With the function `pd.read_csv()`, this function take a string as an argument which correspond to the url or the path of the file (i.e `\"../data/filename.csv\"`). Load the different files: `google-play-store-apps/googleplaystore_user_reviews.csv` and `google-play-store-apps/googleplaystore.csv`. If you use google collab you can fill the `read_csv()` with the url on github repository: \n",
        "\n",
        "**Example:**\n",
        "```python\n",
        "url_reviews = \"https://raw.githubusercontent.com/michalis0/Business-Intelligence-and-Analytics/master/data/google-play-store-apps/googleplaystore_user_reviews.csv\"\n",
        "data_app_reviews = pd.read_csv(url_reviews)\n",
        "```\n",
        "\n",
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ArMjlRvFnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt17aKbovFnS",
        "colab_type": "text"
      },
      "source": [
        "2) Chek the data by using the function `.head()`(beginning of the list), `.tail()` (end of the list), `.columns` (column names), `.index` (raw identifier) and `.dtypes` (column types) (the `display(df.head()`) function can be useful to display the dataframe directly without waiting for the output. \n",
        "\n",
        "**Hint:**\n",
        "```python\n",
        "display(data_app_reviews.head())\n",
        "display(data_app_reviews.columns)\n",
        "```\n",
        "\n",
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PueLvW0PvFnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JZt-FqS0vFnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAQqlM26vFnm",
        "colab_type": "text"
      },
      "source": [
        "3) Look at the different types of the columns. Most of them are Object type, the most general one, we will convert correctly the type of each column. Convert each column types to a correct one. You can use the function `pd.to_numeric()` (give you either a int64 or float64 dtype) or `pd.as_type()`:\n",
        "\n",
        "\n",
        "\n",
        "![](https://pbpython.com/images/pandas_dtypes.png)\n",
        "\n",
        "**Example: How to use astype**\n",
        "```python\n",
        "# convert all DataFrame columns to the int64 dtype\n",
        "df = df.astype(int)\n",
        "\n",
        "# convert column \"a\" to int64 dtype and \"b\" to complex type\n",
        "df = df.astype({\"a\": int, \"b\": complex})\n",
        "\n",
        "# convert Series to float16 type\n",
        "s = s.astype(np.float16)\n",
        "\n",
        "# convert Series to Python strings\n",
        "s = s.astype(str)\n",
        "\n",
        "# convert Series to categorical type - see docs for more details\n",
        "s = s.astype('category')\n",
        "```\n",
        "But here to_numeric() is sufficient! Use the argument `errors = 'ignore'`to deal with string values inside the column. You will encounter some errors during the process, check how to progressively clean the data. To suppress coma and dots use : `.str.replace(\".\",\"\")`on your column.\n",
        "\n",
        "**Example:**\n",
        "To modify the string format to a numerical format when you have some letters like M for billion and k for thousands you can use the following:\n",
        "```python\n",
        "data_app['Reviews'] = data_app[\"Reviews\"].str.replace(\".\",\"\") # suppress comas\n",
        "data_app['Reviews'] = pd.to_numeric(data_app['Reviews'].map(lambda x: str(x)[:-1] + \"000000\" if str(x)[-1] == 'M' else str(x)[:-1] + \"000\"))\n",
        "\n",
        "```\n",
        "The `map()` function apply a function to the all column. The lambda expression is a particular form in python to define a function. Some explanation of the example:   \n",
        "-`lambda`special character to specify a lambda expression for a function  \n",
        "-x is a variable that represent the value of column/raw,   \n",
        "-`str(x)[:-1] + \"000000\"` corresponds to the new value (instead of x), note that we delete the last character and we add `\"000000\"`to the string if the last character is `M`.  \n",
        "-`.str.replace(\".\",\"\")`first transform the `Object` type to a string, then replace the dot by a empty character.\n",
        "\n",
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I8v3Gy1vFno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGyvggnnvFns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0d2fZe2vFnx",
        "colab_type": "text"
      },
      "source": [
        "4) Note that there exists some null values. For each dataframe, count the number of null values by using: `.isnull()` and `.sum()`. Drop the null values if there exist. Print the shape of your dataframes before and after the cleaning process: `.shape`. How many data was deleted ?\n",
        "\n",
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh4BS1SYvFny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TZyrV1xvFn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we6xjLCpvFn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QNGjUe_vFoB",
        "colab_type": "text"
      },
      "source": [
        "4) We will apply now some selections/filters on the data:  \n",
        "    - filter  the data reviews where the Sentiment_Subjectivity mean  > 0.5 , use: `grouby()`, `mean()` and `where()`  \n",
        "    - select the 10 best reviewed apps, use `.sort_values()`  \n",
        "    - select the gender which have the higher ranking  mean: use `groupby()`, `mean()`and `sort_values()`\n",
        "    \n",
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCPiPyHE7Zu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynzzwQJ5-dNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI1mTR_S_XsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}